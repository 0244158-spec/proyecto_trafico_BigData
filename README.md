# Proyecto Final â€“ AnÃ¡lisis de TrÃ¡fico con LLM y SQL Agent

Este proyecto carga un dataset masivo de trÃ¡fico (~3.9 millones de registros) a una base de datos PostgreSQL en Supabase y permite hacer anÃ¡lisis usando un **agente de lenguaje natural**.  
El usuario escribe una pregunta en espaÃ±ol (por ejemplo: *"Â¿CuÃ¡l es el trÃ¡fico promedio por hora del dÃ­a?"*) y un **LLM (modelo de OpenAI)** genera la consulta SQL, la ejecuta contra la tabla `trafico_amg_clean` y devuelve los resultados.

---

## Arquitectura General del Proyecto

El proyecto sigue una arquitectura tipo **Medallion** con dos capas principales y un agente inteligente para anÃ¡lisis dinÃ¡mico.

            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚         CSV RAW           â”‚
            â”‚   (3.9 millones rows)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     Bronze Layer         â”‚
            â”‚   trafico_amg (raw)      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     Silver Layer         â”‚
            â”‚ trafico_amg_clean (ETL)  â”‚
            â”‚ limpieza y tipos correctosâ”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   LLM SQL Agent (Python) â”‚
            â”‚ Pregunta â†’ SQL â†’ Result  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

### Bronze (trafico_amg)
- Contiene los datos originales del CSV.
- Todos los tipos vienen como texto.
- Puede contener errores o valores fuera de formato.

### Silver (trafico_amg_clean)
- Campos convertidos correctamente a:
  - `numeric`  
  - `timestamp`  
  - `text`
- Filas invÃ¡lidas eliminadas.
- Lista para anÃ¡lisis real.

### Agente LLM-SQL
- Genera SQL basada en lenguaje natural.
- Ejecuta consultas automÃ¡ticas.
- Responde al usuario con tablas de resultados.

---


## Carga del Dataset (Bronze Layer)

El dataset original contenÃ­a alrededor de **3.9 millones de registros de trÃ¡fico**, cada uno con:

- color predominante,
- ponderaciones de color,
- lÃ³gica difusa de trÃ¡fico,
- coordenadas (lat/long),
- fecha y hora en diversos formatos.

Debido al tamaÃ±o, el archivo CSV excedÃ­a los lÃ­mites de carga directa, por lo que se dividiÃ³ en partes mÃ¡s pequeÃ±as y se insertÃ³ mediante:

- `psql` con `\copy`  
- o el cargador de CSV de Supabase cuando fue posible  

La tabla creada para el RAW fue:

```sql
CREATE TABLE trafico_amg (
    id text,
    predominant_color text,
    exponential_color_weighting text,
    linear_color_weighting text,
    diffuse_logic_traffic text,
    dtime text,
    lat text,
    long text
);
```
---

## Limpieza y TransformaciÃ³n (Silver Layer)

Para convertir los datos en un formato analizable, se creÃ³ la tabla:
trafico_amg_clean


mediante una transformaciÃ³n SQL que:

1. **ConvertÃ­a valores numÃ©ricos**  
2. **ConvertÃ­a fechas** usando `TO_TIMESTAMP`  
3. **Eliminaba registros corruptos**  
4. **Tipaba correctamente las columnas**

CÃ³digo utilizado:

```sql
CREATE TABLE trafico_amg_clean AS
SELECT
    CAST(id AS numeric) AS id,
    predominant_color,
    CAST(exponential_color_weighting AS numeric) AS exponential_color_weighting,
    CAST(linear_color_weighting AS numeric) AS linear_color_weighting,
    diffuse_logic_traffic,
    TO_TIMESTAMP(dtime, 'YYYYMMDDHH24MISS') AS dtime,
    CAST(lat AS numeric) AS lat,
    CAST(long AS numeric) AS long
FROM trafico_amg
WHERE
    exponential_color_weighting ~ '^[0-9\.]+$' AND
    linear_color_weighting ~ '^[0-9\.]+$' AND
    lat ~ '^-?[0-9\.]+$' AND
    long ~ '^-?[0-9\.]+$';
```
Esto generÃ³ una tabla final limpia, tipada y lista para anÃ¡lisis, cumpliendo los principios de la capa Silver de la arquitectura Medallion.



ConstrucciÃ³n del Agente LLM con conexiÃ³n a PostgreSQL

Para permitir que el usuario hiciera preguntas en lenguaje natural y que el modelo generara consultas SQL automÃ¡ticamente, construimos un agente LLMâ€“SQL usando:

Python

OpenAI (gpt-4o-mini / gpt-4.1)

psycopg2 (cliente PostgreSQL)

Un "tool" que valida y ejecuta SQL generado por el LLM

SanitizaciÃ³n bÃ¡sica del SQL para evitar errores

InstalaciÃ³n de dependencias
pip install openai psycopg2 python-dotenv


Creamos un entorno virtual:

python3 -m venv venv
source venv/bin/activate

Variables de entorno

Creamos un archivo .env:

OPENAI_API_KEY=sk-XXXXXX
DB_HOST=aws-1-us-east-2.pooler.supabase.com
DB_PORT=5432
DB_NAME=postgres
DB_USER=postgres.tuppqwbnfhdbijyppodq
DB_PASSWORD= TU_PASSWORD_AQUI

LÃ³gica del agente (agent_trafico.py)

Este archivo contiene:

ConexiÃ³n a PostgreSQL

DefiniciÃ³n del â€œtoolâ€ que ejecuta SQL

Instrucciones al agente para que solo genere SQL vÃ¡lido

Un ciclo interactivo donde el usuario puede preguntar lo que quiera

AquÃ­ estÃ¡ el cÃ³digo completo que debes poner en tu README:

import os
import psycopg2
from dotenv import load_dotenv
from openai import OpenAI

# Inicializar cliente OpenAI
client = OpenAI(api_key=API_KEY)

# -------------------------------------------------------------------
# FUNCIÃ“N: Ejecutar SQL de forma segura
# -------------------------------------------------------------------
def run_sql_query(query):
    try:
        # Sanitizar: eliminar ```sql y ```
        query = query.replace("```sql", "").replace("```", "").strip()

        conn = psycopg2.connect(
            host=DB_HOST,
            port=DB_PORT,
            dbname=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD
        )
        cur = conn.cursor()
        cur.execute(query)

        try:
            rows = cur.fetchall()
        except:
            rows = []

        headers = [d[0] for d in cur.description] if cur.description else []
        conn.commit()

        cur.close()
        conn.close()

        return {"headers": headers, "rows": rows}

    except Exception as e:
        return {"error": str(e)}


# DefiniciÃ³n del TOOL para OpenAI
tools = [
    {
        "type": "function",
        "function": {
            "name": "run_sql_query",
            "description": "Ejecuta una consulta SQL en PostgreSQL",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string"}
                },
                "required": ["query"]
            }
        }
    }
]

# -------------------------------------------------------------------
# LOOP INTERACTIVO DEL AGENTE
# -------------------------------------------------------------------
def main():
    print("Asistente de trÃ¡fico LLM-SQL conectado a trafico_amg_clean")
    print("Escribe tu pregunta en lenguaje natural. Escribe 'salir' para terminar.\n")

    while True:
        pregunta = input("Pregunta: ")
        if pregunta.lower() == "salir":
            break

        # Llamada al modelo
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Eres un asistente experto en SQL. "
                        "Tu trabajo es generar Ãºnicamente SQL vÃ¡lido para PostgreSQL "
                        "sobre la tabla trafico_amg_clean. "
                        "Nunca expliques, solo genera SQL."
                    )
                },
                {"role": "user", "content": pregunta}
            ],
            tools=tools,
            tool_choice="auto"
        )

        msg = response.choices[0].message

        # Â¿El modelo llamÃ³ al TOOL?
        if msg.tool_calls:
            sql_code = msg.tool_calls[0].function.arguments
            import json
            sql_code = json.loads(sql_code)["query"]

            print("\nðŸ”§ SQL generada por el modelo:\n", sql_code, "\n")

            result = run_sql_query(sql_code)

            if "error" in result:
                print("âŒ Error al ejecutar SQL:", result["error"])
            else:
                print("ðŸ“Š Resultados:")
                for row in result["rows"]:
                    print(row)

            print("\n" + "="*80 + "\n")

        else:
            print("El modelo no generÃ³ SQL.")

if __name__ == "__main__":
    main()

Ejemplo funcionando

Consulta del usuario:

Â¿CuÃ¡l es el trÃ¡fico promedio por hora del dÃ­a?

SQL generada automÃ¡ticamente:

SELECT
    EXTRACT(HOUR FROM dtime) AS hora,
    AVG(exponential_color_weighting) AS trafico_promedio
FROM trafico_amg_clean
GROUP BY hora
ORDER BY hora;


Resultado:

hora | trafico_promedio
-------------------------
1    | 508.29
2    | 508.29
3    | 508.29
...

## Â¿QuÃ© permite este agente?

El usuario puede preguntar:

>â€œÂ¿QuÃ© trÃ¡fico hay en un punto (lat,long)?â€

>â€œÂ¿QuÃ© hora del dÃ­a tiene mÃ¡s trÃ¡fico?â€

>â€œÂ¿CuÃ¡l es el color predominante mÃ¡s comÃºn?â€

>â€œDame un histograma por horaâ€

>â€œÂ¿DÃ³nde se registran valores anÃ³malos?â€

>â€œÂ¿QuÃ© zonas tienen trÃ¡fico por arriba del percentil 90?â€

Todo en lenguaje natural â†’ SQL automÃ¡tico â†’ ejecuciÃ³n real en PostgreSQL.

---

## ðŸ“Š AnÃ¡lisis realizados con el agente LLM-SQL
 
A continuaciÃ³n se describen los anÃ¡lisis implementados, cada uno con:

- Pregunta en lenguaje natural  
- SQL generada (o equivalente)  
- InterpretaciÃ³n del resultado  

---

### TrÃ¡fico promedio por hora del dÃ­a

**Pregunta (usuario):**

> Â¿CuÃ¡l es el trÃ¡fico promedio (exponential_color_weighting) por hora del dÃ­a?

**SQL generada:**

SELECT
    EXTRACT(HOUR FROM dtime) AS hora,
    AVG(exponential_color_weighting) AS trafico_promedio
FROM trafico_amg_clean
GROUP BY hora
ORDER BY hora;

InterpretaciÃ³n:
Permite identificar cuÃ¡les son las horas con mayor intensidad de trÃ¡fico promedio en toda la ciudad.

TrÃ¡fico promedio por dÃ­a de la semana

**Pregunta (usuario):**

>Â¿QuÃ© dÃ­a de la semana tiene mayor trÃ¡fico promedio?

**SQL generada:**

SELECT
    TO_CHAR(dtime, 'Day') AS dia_semana,
    AVG(exponential_color_weighting) AS trafico_promedio
FROM trafico_amg_clean
GROUP BY dia_semana
ORDER BY trafico_promedio DESC;


InterpretaciÃ³n:
Permite encontrar quÃ© dÃ­as (lunes, martes, etc.) presentan mayor congestiÃ³n en promedio.

Zonas de mayor congestiÃ³n (heatmap simplificado)

**Pregunta (usuario):**

>Â¿CuÃ¡les son las zonas con mayor trÃ¡fico promedio?

**SQL generada:**

SELECT
    ROUND(lat, 3) AS grid_lat,
    ROUND(long, 3) AS grid_long,
    AVG(exponential_color_weighting) AS trafico_promedio,
    COUNT(*) AS registros
FROM trafico_amg_clean
GROUP BY grid_lat, grid_long
ORDER BY trafico_promedio DESC
LIMIT 50;


InterpretaciÃ³n:
Agrupa puntos cercanos (por coordenadas) y devuelve las â€œceldasâ€ con mayor trÃ¡fico promedio, Ãºtil para construir un mapa de calor.

Puntos con mayor trÃ¡fico rojo

**Pregunta (usuario):**

>Â¿En quÃ© coordenadas se presenta mÃ¡s trÃ¡fico rojo?

**SQL generada:**

SELECT
    lat,
    long,
    COUNT(*) AS veces_rojo
FROM trafico_amg_clean
WHERE predominant_color = 'red'
GROUP BY lat, long
ORDER BY veces_rojo DESC
LIMIT 20;


InterpretaciÃ³n:
Identifica las coordenadas donde mÃ¡s veces se detecta el color predominante â€œredâ€, asociado a alto trÃ¡fico o congestiÃ³n.

DistribuciÃ³n por tipo de trÃ¡fico (diffuse_logic_traffic)

**Pregunta (usuario):**

>Â¿CÃ³mo se reparte el trÃ¡fico por tipo de diffuse_logic_traffic?

**SQL generada:**

SELECT
    diffuse_logic_traffic,
    COUNT(*) AS registros
FROM trafico_amg_clean
GROUP BY diffuse_logic_traffic
ORDER BY registros DESC;


InterpretaciÃ³n:
Muestra quÃ© categorÃ­as lÃ³gicas de trÃ¡fico (segÃºn el campo diffuse_logic_traffic) son mÃ¡s frecuentes en el dataset.

(Opcional) Tendencia mensual del trÃ¡fico

**Pregunta (usuario):**

>Â¿CÃ³mo ha cambiado el trÃ¡fico promedio por mes?

**SQL generada:**

SELECT
    DATE_TRUNC('month', dtime) AS mes,
    AVG(exponential_color_weighting) AS trafico_promedio
FROM trafico_amg_clean
GROUP BY mes
ORDER BY mes;


InterpretaciÃ³n:
Sirve para construir una serie de tiempo mensual y analizar si el trÃ¡fico aumenta, disminuye o se mantiene estable.
