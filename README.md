# Proyecto Final ‚Äì An√°lisis de Tr√°fico con LLM y SQL Agent

Este proyecto carga un dataset masivo de tr√°fico (~3.9 millones de registros) a una base de datos PostgreSQL en Supabase y permite hacer an√°lisis usando un **agente de lenguaje natural**.  
El usuario escribe una pregunta en espa√±ol (por ejemplo: *"¬øCu√°l es el tr√°fico promedio por hora del d√≠a?"*) y un **LLM (modelo de OpenAI)** genera la consulta SQL, la ejecuta contra la tabla `trafico_amg_clean` y devuelve los resultados.

---

## üèóÔ∏èArquitectura General del Proyecto

El proyecto sigue una arquitectura tipo **Medallion** con dos capas principales y un agente inteligente para an√°lisis din√°mico.

            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ         CSV RAW           ‚îÇ
            ‚îÇ   (3.9 millones rows)     ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ     Bronze Layer         ‚îÇ
            ‚îÇ   trafico_amg (raw)      ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ     Silver Layer         ‚îÇ
            ‚îÇ trafico_amg_clean (ETL)  ‚îÇ
            ‚îÇ limpieza y tipos correctos‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   LLM SQL Agent (Python) ‚îÇ
            ‚îÇ Pregunta ‚Üí SQL ‚Üí Result  ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

### üü§ Bronze (trafico_amg)
- Contiene los datos originales del CSV.
- Todos los tipos vienen como texto.
- Puede contener errores o valores fuera de formato.

### ‚ö™ Silver (trafico_amg_clean)
- Campos convertidos correctamente a:
  - `numeric`  
  - `timestamp`  
  - `text`
- Filas inv√°lidas eliminadas.
- Lista para an√°lisis real.

### ü§ñ Agente LLM-SQL
- Genera SQL basada en lenguaje natural.
- Ejecuta consultas autom√°ticas.
- Responde al usuario con tablas de resultados.

---


## üì• Carga del Dataset (Bronze Layer)

El dataset original conten√≠a alrededor de **3.9 millones de registros de tr√°fico**, cada uno con:

- color predominante,
- ponderaciones de color,
- l√≥gica difusa de tr√°fico,
- coordenadas (lat/long),
- fecha y hora en diversos formatos.

Debido al tama√±o, el archivo CSV exced√≠a los l√≠mites de carga directa, por lo que se dividi√≥ en partes m√°s peque√±as y se insert√≥ mediante:

- `psql` con `\copy`  
- o el cargador de CSV de Supabase cuando fue posible  

La tabla creada para el RAW fue:

```sql
CREATE TABLE trafico_amg (
    id text,
    predominant_color text,
    exponential_color_weighting text,
    linear_color_weighting text,
    diffuse_logic_traffic text,
    dtime text,
    lat text,
    long text
);
```
---

## Limpieza y Transformaci√≥n (Silver Layer)

Para convertir los datos en un formato analizable, se cre√≥ la tabla:
trafico_amg_clean


mediante una transformaci√≥n SQL que:

1. **Convert√≠a valores num√©ricos**  
2. **Convert√≠a fechas** usando `TO_TIMESTAMP`  
3. **Eliminaba registros corruptos**  
4. **Tipaba correctamente las columnas**

C√≥digo utilizado:

```sql
CREATE TABLE trafico_amg_clean AS
SELECT
    CAST(id AS numeric) AS id,
    predominant_color,
    CAST(exponential_color_weighting AS numeric) AS exponential_color_weighting,
    CAST(linear_color_weighting AS numeric) AS linear_color_weighting,
    diffuse_logic_traffic,
    TO_TIMESTAMP(dtime, 'YYYYMMDDHH24MISS') AS dtime,
    CAST(lat AS numeric) AS lat,
    CAST(long AS numeric) AS long
FROM trafico_amg
WHERE
    exponential_color_weighting ~ '^[0-9\.]+$' AND
    linear_color_weighting ~ '^[0-9\.]+$' AND
    lat ~ '^-?[0-9\.]+$' AND
    long ~ '^-?[0-9\.]+$';
```
Esto gener√≥ una tabla final limpia, tipada y lista para an√°lisis, cumpliendo los principios de la capa Silver de la arquitectura Medallion.



Construcci√≥n del Agente LLM con conexi√≥n a PostgreSQL

Para permitir que el usuario hiciera preguntas en lenguaje natural y que el modelo generara consultas SQL autom√°ticamente, construimos un agente LLM‚ÄìSQL usando:

Python

OpenAI (gpt-4o-mini / gpt-4.1)

psycopg2 (cliente PostgreSQL)

Un "tool" que valida y ejecuta SQL generado por el LLM

Sanitizaci√≥n b√°sica del SQL para evitar errores

Instalaci√≥n de dependencias
pip install openai psycopg2 python-dotenv


Creamos un entorno virtual:

python3 -m venv venv
source venv/bin/activate

Variables de entorno

Creamos un archivo .env:

OPENAI_API_KEY=sk-XXXXXX
DB_HOST=aws-1-us-east-2.pooler.supabase.com
DB_PORT=5432
DB_NAME=postgres
DB_USER=postgres.tuppqwbnfhdbijyppodq
DB_PASSWORD= TU_PASSWORD_AQUI

L√≥gica del agente (agent_trafico.py)

Este archivo contiene:

Conexi√≥n a PostgreSQL

Definici√≥n del ‚Äútool‚Äù que ejecuta SQL

Instrucciones al agente para que solo genere SQL v√°lido

Un ciclo interactivo donde el usuario puede preguntar lo que quiera

Aqu√≠ est√° el c√≥digo completo que debes poner en tu README:

import os
import psycopg2
from dotenv import load_dotenv
from openai import OpenAI

# Inicializar cliente OpenAI
client = OpenAI(api_key=API_KEY)

# -------------------------------------------------------------------
# FUNCI√ìN: Ejecutar SQL de forma segura
# -------------------------------------------------------------------
def run_sql_query(query):
    try:
        # Sanitizar: eliminar ```sql y ```
        query = query.replace("```sql", "").replace("```", "").strip()

        conn = psycopg2.connect(
            host=DB_HOST,
            port=DB_PORT,
            dbname=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD
        )
        cur = conn.cursor()
        cur.execute(query)

        try:
            rows = cur.fetchall()
        except:
            rows = []

        headers = [d[0] for d in cur.description] if cur.description else []
        conn.commit()

        cur.close()
        conn.close()

        return {"headers": headers, "rows": rows}

    except Exception as e:
        return {"error": str(e)}


# Definici√≥n del TOOL para OpenAI
tools = [
    {
        "type": "function",
        "function": {
            "name": "run_sql_query",
            "description": "Ejecuta una consulta SQL en PostgreSQL",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string"}
                },
                "required": ["query"]
            }
        }
    }
]

# -------------------------------------------------------------------
# LOOP INTERACTIVO DEL AGENTE
# -------------------------------------------------------------------
def main():
    print("Asistente de tr√°fico LLM-SQL conectado a trafico_amg_clean")
    print("Escribe tu pregunta en lenguaje natural. Escribe 'salir' para terminar.\n")

    while True:
        pregunta = input("Pregunta: ")
        if pregunta.lower() == "salir":
            break

        # Llamada al modelo
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Eres un asistente experto en SQL. "
                        "Tu trabajo es generar √∫nicamente SQL v√°lido para PostgreSQL "
                        "sobre la tabla trafico_amg_clean. "
                        "Nunca expliques, solo genera SQL."
                    )
                },
                {"role": "user", "content": pregunta}
            ],
            tools=tools,
            tool_choice="auto"
        )

        msg = response.choices[0].message

        # ¬øEl modelo llam√≥ al TOOL?
        if msg.tool_calls:
            sql_code = msg.tool_calls[0].function.arguments
            import json
            sql_code = json.loads(sql_code)["query"]

            print("\nüîß SQL generada por el modelo:\n", sql_code, "\n")

            result = run_sql_query(sql_code)

            if "error" in result:
                print("‚ùå Error al ejecutar SQL:", result["error"])
            else:
                print("üìä Resultados:")
                for row in result["rows"]:
                    print(row)

            print("\n" + "="*80 + "\n")

        else:
            print("El modelo no gener√≥ SQL.")

if __name__ == "__main__":
    main()

Ejemplo funcionando

Consulta del usuario:

¬øCu√°l es el tr√°fico promedio por hora del d√≠a?

SQL generada autom√°ticamente:

SELECT
    EXTRACT(HOUR FROM dtime) AS hora,
    AVG(exponential_color_weighting) AS trafico_promedio
FROM trafico_amg_clean
GROUP BY hora
ORDER BY hora;


Resultado:

hora | trafico_promedio
-------------------------
1    | 508.29
2    | 508.29
3    | 508.29
...

¬øQu√© permite este agente?

El usuario puede preguntar:

‚Äú¬øQu√© tr√°fico hay en un punto (lat,long)?‚Äù

‚Äú¬øQu√© hora del d√≠a tiene m√°s tr√°fico?‚Äù

‚Äú¬øCu√°l es el color predominante m√°s com√∫n?‚Äù

‚ÄúDame un histograma por hora‚Äù

‚Äú¬øD√≥nde se registran valores an√≥malos?‚Äù

‚Äú¬øQu√© zonas tienen tr√°fico por arriba del percentil 90?‚Äù

Todo en lenguaje natural ‚Üí SQL autom√°tico ‚Üí ejecuci√≥n real en PostgreSQL.

---

## üìä An√°lisis realizados con el agente LLM-SQL

El profesor solicita al menos **5 tipos de an√°lisis diferentes** utilizando esta tecnolog√≠a.  
A continuaci√≥n se describen los an√°lisis implementados, cada uno con:

- Pregunta en lenguaje natural  
- SQL generada (o equivalente)  
- Interpretaci√≥n del resultado  

---

### Tr√°fico promedio por hora del d√≠a

**Pregunta (usuario):**

> ¬øCu√°l es el tr√°fico promedio (exponential_color_weighting) por hora del d√≠a?

**SQL generada:**

```sql
SELECT
    EXTRACT(HOUR FROM dtime) AS hora,
    AVG(exponential_color_weighting) AS trafico_promedio
FROM trafico_amg_clean
GROUP BY hora
ORDER BY hora;

Interpretaci√≥n:
Permite identificar cu√°les son las horas con mayor intensidad de tr√°fico promedio en toda la ciudad.

Tr√°fico promedio por d√≠a de la semana

Pregunta (usuario):

¬øQu√© d√≠a de la semana tiene mayor tr√°fico promedio?

SQL generada:

SELECT
    TO_CHAR(dtime, 'Day') AS dia_semana,
    AVG(exponential_color_weighting) AS trafico_promedio
FROM trafico_amg_clean
GROUP BY dia_semana
ORDER BY trafico_promedio DESC;


Interpretaci√≥n:
Permite encontrar qu√© d√≠as (lunes, martes, etc.) presentan mayor congesti√≥n en promedio.

Zonas de mayor congesti√≥n (heatmap simplificado)

Pregunta (usuario):

¬øCu√°les son las zonas con mayor tr√°fico promedio?

SQL generada:

SELECT
    ROUND(lat, 3) AS grid_lat,
    ROUND(long, 3) AS grid_long,
    AVG(exponential_color_weighting) AS trafico_promedio,
    COUNT(*) AS registros
FROM trafico_amg_clean
GROUP BY grid_lat, grid_long
ORDER BY trafico_promedio DESC
LIMIT 50;


Interpretaci√≥n:
Agrupa puntos cercanos (por coordenadas) y devuelve las ‚Äúceldas‚Äù con mayor tr√°fico promedio, √∫til para construir un mapa de calor.

Puntos con mayor tr√°fico rojo

Pregunta (usuario):

¬øEn qu√© coordenadas se presenta m√°s tr√°fico rojo?

SQL generada:

SELECT
    lat,
    long,
    COUNT(*) AS veces_rojo
FROM trafico_amg_clean
WHERE predominant_color = 'red'
GROUP BY lat, long
ORDER BY veces_rojo DESC
LIMIT 20;


Interpretaci√≥n:
Identifica las coordenadas donde m√°s veces se detecta el color predominante ‚Äúred‚Äù, asociado a alto tr√°fico o congesti√≥n.

Distribuci√≥n por tipo de tr√°fico (diffuse_logic_traffic)

Pregunta (usuario):

¬øC√≥mo se reparte el tr√°fico por tipo de diffuse_logic_traffic?

SQL generada:

SELECT
    diffuse_logic_traffic,
    COUNT(*) AS registros
FROM trafico_amg_clean
GROUP BY diffuse_logic_traffic
ORDER BY registros DESC;


Interpretaci√≥n:
Muestra qu√© categor√≠as l√≥gicas de tr√°fico (seg√∫n el campo diffuse_logic_traffic) son m√°s frecuentes en el dataset.

5.6 (Opcional) Tendencia mensual del tr√°fico

Pregunta (usuario):

¬øC√≥mo ha cambiado el tr√°fico promedio por mes?

SQL generada:

SELECT
    DATE_TRUNC('month', dtime) AS mes,
    AVG(exponential_color_weighting) AS trafico_promedio
FROM trafico_amg_clean
GROUP BY mes
ORDER BY mes;


Interpretaci√≥n:
Sirve para construir una serie de tiempo mensual y analizar si el tr√°fico aumenta, disminuye o se mantiene estable.
